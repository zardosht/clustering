
order of point doesn't imply order in presentation :P

part 1) visualization
 		1.1 Dot Cloud 
 			1.1.1 Unclustered image -> show that data set is crappy
 			1.1.2 Clustered Image
 			1.1.3 Clustered image with sorted by keyword occurence (in order to see hot spots)
 			1.1.4 dimension reduction (clustered/unclustered)
 			
 		1.2 show that force graph doesn't work (gephi graphs)
 		
 		1.3 Hierarchical clustering
 			* big image 
 			* smaller images (lower item count) with filters, skewing etc
 			* image with selected group of items (two similar groups, kids and action movies, to show how it works)
 			* try different distance measures
 			
part 2) theory
		1.1 distances
			1.1.1 OTUs (a, b, c, d). refer to the paper "survey of distance for binary data"
			1.1.2 describe distances that we used, compare results about distances (describe RSS), diagrams, visualization.
		1.2 hierarchical algorithms
			1.2.1 Single-link, Complete link, AvgLink, with corresponding visualization
		1.3 filters
			1.3.1. data about dataset (histogram for keyword counts), reducing dimension
			1.3.2. what we do to filter data
 		

todo: 
1. create a folder for final stuff DONE

2. create dot-map for unfiltered items
3. create dot-map for unfiltered items with sorted keywords
4. create dot-map for filtered items with atLeast2, atLeast5, and atLeast10 keywords
5. create dot-map for clustered items with sorted keywords only with atLeast2 keywords using 2 different distances (otsuka, russell_and_rao)
6. create dot-map for clustered items with sorted keywords only with atLeast10 keywords using 2 different distances (otsuka, russell_and_rao)

7. create keywords histogram

8. export flat clustering data for k for 2 distances (Otsuka, and russell) with atLeast2 keywords
9. export flat clustering data for k for 2 distances (Otsuka, and russell) with atLeast10 keywords
10. create K-RSS diagram for step 8 and 9

11. create dendrogram for filtered items using atLeast2 keywords using AvgDistAlg (the big photo)
12. create dendrogram for filtered items using atLeast10 keywords using AvgDistAlg
13. find two groups of similar films (for example actions and romances)(manually). create dendrogram. See if dendrogram 
    shows the two main groups or not. 

14. create presentation.

***** gephi









****************************************************************

1. Add two other implementations of distance. DONE
2. Compare k-means results with a third distance measure that is not used in clustering. 
   Also Use different seed selection strategies (random vs. choosing seed as the
   centroid of i randomly selected vectors)
3. Find good combinations of distance function and K. 
4. Visualize results from step 3
5. Implement hierarchical clustering and visualize its results 
6. (nice to have) Implement text categorization and visualize its results. 
7. Creates slides for presentation.

Notes:

1. We use k-medoid method. Medoid of a cluster is the document vector that is closest to the
centroid.


****************************************************************
Alg:
====
Wahl K;
Auswahl von K Elementen als initiale Centroide;
<repeat>{
Bilde K Cluster durch Zuweisen aller Element zum Centroid mit der geringsten Entfernung;
Berechne die Centroide aller Cluster neu;
}<until> Centroide ändern sich nicht mehr;

****************************************************************

• FilmID – Keyword-Tabelle wird bereitgestellt
	– Ergebnis von Block 2
• Ziel: Finde ähnliche Filme zu einem gegebenen Film mit KMeans Clustering
• Wesentliche Entscheidungen bei Implementierung K-Means
	– Wahl K
	– Repräsentation Centroid, z.B. Schlüsselwörter eines Filmes oder Obermenge aller Schlüsselwörter eines Clusters
	– Wahl der initialen Centroide, z.B. zufällig (oder Heuristik möglich?)
• Analyse des Clusterings anhand Zahl der Filme in Cluster für mind. drei Werte von K
	– Was ist das beste K?
	
===============================================================